{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "# Add the parent directory to the sys.path list\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import NAS.utils as utils\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.166996002197266\n",
      "RMSE: 0.6330188775973445 R^2 score: -48.39569117317432\n"
     ]
    }
   ],
   "source": [
    "from reservoirpy.nodes import (Reservoir, Ridge, IPReservoir, NVAR, RLS, Input)\n",
    "import numpy as np\n",
    "from reservoirpy.datasets import narma, lorenz96\n",
    "from reservoirpy.observables import rmse, rsquare\n",
    "\n",
    "X = narma(n_timesteps=2000)\n",
    "\n",
    "sampleX = np.random.rand(10000, 1)\n",
    "\n",
    "reservoir1 = Reservoir(units=500, lr=0.3, sr=1.25)\n",
    "reservoir2 = Reservoir(units=500, lr=0.3, sr=1.25)\n",
    "readout = Ridge(output_dim=1, ridge=1e-5)\n",
    "# reservoir2 <<= readout\n",
    "esn = reservoir1 >> reservoir2 >> readout\n",
    "def func():\n",
    "    esn.fit(X[:500], X[1:501], warmup=100, force_teachers=True)\n",
    "\n",
    "memoryUsed = measure_memory_usage(func)\n",
    "print(memoryUsed)\n",
    "predictions = esn.run(X[501:-1])\n",
    "nodeNames = [node.name for node in esn.nodes]\n",
    "# predictions = predictions[nodeNames[-1]]\n",
    "print(\"RMSE:\", rmse(X[502:], predictions), \"R^2 score:\", rsquare(X[502:], predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    df = pd.read_csv(\"../data/electricity.csv\", index_col=\"Unnamed: 0\")\n",
    "    df.index = pd.to_datetime(df['Date'] + \" \" + df['Time'])\n",
    "    df = df.sort_index()\n",
    "    df = df.iloc[-100000:]\n",
    "\n",
    "    df['Target_active_power'] = df['Global_active_power'].shift(-1)\n",
    "    df = df.replace(\"?\", np.nan).ffill().dropna()\n",
    "\n",
    "    T = len(df)\n",
    "    valid_boundary = 0.6\n",
    "    test_boundary = 0.8\n",
    "    valid_index = int(T*valid_boundary)\n",
    "    test_index = int(T*test_boundary)\n",
    "    train = df.iloc[:valid_index, 2:].to_numpy().astype(float)\n",
    "    val = df.iloc[valid_index:test_index, 2:].to_numpy().astype(float)\n",
    "    test = df.iloc[test_index:, 2:].to_numpy().astype(float)\n",
    "    trainX = train[:, :-1]\n",
    "    trainY = train[:, -1:]\n",
    "    valX = val[:, :-1]\n",
    "    valY = val[:, -1:]\n",
    "    testX = test[:, :-1]\n",
    "    testY = test[:, -1:]\n",
    "    return trainX, trainY, valX, valY, testX, testY\n",
    "\n",
    "trainX, trainY, valX, valY, testX, testY = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    water = pd.read_csv(\"../datasets/Water.csv\").to_numpy()\n",
    "    trainLen = math.floor(len(water)*0.5)\n",
    "    valLen = math.floor(len(water)*0.7)\n",
    "    \n",
    "    train_in = water[0:trainLen, :18]\n",
    "    train_out = water[0:trainLen, 18:]\n",
    "    val_in = water[trainLen:valLen, :18]\n",
    "    val_out = water[trainLen:valLen, 18:]\n",
    "    test_in = water[valLen:, :18]\n",
    "    test_out = water[valLen:, 18:]\n",
    "    return train_in, train_out, val_in, val_out, test_in, test_out\n",
    "\n",
    "trainX, trainY, valX, valY, testX, testY = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1171.9860248565674 837.9480812072754\n"
     ]
    }
   ],
   "source": [
    "from NAS.memory_estimator import measure_memory_usage\n",
    "\n",
    "architecture = utils.generateRandomArchitecture(trainX.shape[1], trainY.shape[1], trainX.shape[0], memoryLimit=1024)\n",
    "expected = utils.estimateMemory(architecture, trainX.shape[0])\n",
    "\n",
    "def func():\n",
    "    model = utils.constructModel(architecture)\n",
    "    utils.trainModel(model, trainX, trainY)\n",
    "actual = measure_memory_usage(func)\n",
    "print(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19735, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedData = np.hstack((X.iloc[:, 1:].to_numpy(), y.to_numpy()))\n",
    "combinedData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    from ucimlrepo import fetch_ucirepo\n",
    "    appliances_energy_prediction = fetch_ucirepo(id=374)\n",
    "    X = appliances_energy_prediction.data.features.iloc[:, 1:].to_numpy()\n",
    "    y = appliances_energy_prediction.data.targets.to_numpy()\n",
    "\n",
    "    trainLen = 14000\n",
    "    valLen = 16000\n",
    "    \n",
    "    train_in = X[0:trainLen]\n",
    "    train_out = y[0:trainLen]\n",
    "    val_in = X[trainLen:valLen]\n",
    "    val_out = y[trainLen:valLen]\n",
    "    test_in = X[valLen:]\n",
    "    test_out = y[valLen:]\n",
    "    return train_in, train_out, val_in, val_out, test_in, test_out\n",
    "\n",
    "trainX, trainY, valX, valY, testX, testY = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.datasets._seed import get_seed\n",
    "from reservoirpy.utils.random import rand_generator\n",
    "from reservoirpy.utils.validation import check_vector\n",
    "\n",
    "def narma(\n",
    "    n_timesteps,\n",
    "    order = 30,\n",
    "    a1 = 0.2,\n",
    "    a2 = 0.04,\n",
    "    b = 1.5,\n",
    "    c = 0.001,\n",
    "    x0 = [0.0],\n",
    "    seed = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Non-linear Autoregressive Moving Average (NARMA) timeseries,\n",
    "    as first defined in [14]_, and as used in [15]_.\n",
    "\n",
    "    NARMA n-th order dynamical system is defined by the recurrent relation:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        y[t+1] = a_1 y[t] + a_2 y[t] (\\\\sum_{i=0}^{n-1} y[t-i]) + b u[t-(\n",
    "        n-1)]u[t] + c\n",
    "\n",
    "    where :math:`u[t]` are sampled following a uniform distribution in\n",
    "    :math:`[0, 0.5]`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_timesteps : int\n",
    "        Number of timesteps to generate.\n",
    "    order: int, default to 30\n",
    "        Order of the system.\n",
    "    a1 : float, default to 0.2\n",
    "        :math:`a_1` parameter of the system.\n",
    "    a2 : float, default to 0.04\n",
    "        :math:`a_2` parameter of the system.\n",
    "    b : float, default to 1.5\n",
    "        :math:`b` parameter of the system.\n",
    "    c : float, default to 0.001\n",
    "        :math:`c` parameter of the system.\n",
    "    x0 : array-like of shape (init_steps,), default to [0.0]\n",
    "        Initial conditions of the system.\n",
    "    seed : int or :py:class:`numpy.random.Generator`, optional\n",
    "        Random state seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array of shape (n_timesteps, 1)\n",
    "        NARMA timeseries.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [14] A. F. Atiya and A. G. Parlos, ‘New results on recurrent\n",
    "           network training: unifying the algorithms and accelerating\n",
    "           convergence,‘ in IEEE Transactions on Neural Networks,\n",
    "           vol. 11, no. 3, pp. 697-709, May 2000,\n",
    "           doi: 10.1109/72.846741.\n",
    "\n",
    "    .. [15] B.Schrauwen, M. Wardermann, D. Verstraeten, J. Steil,\n",
    "           D. Stroobandt, ‘Improving reservoirs using intrinsic\n",
    "           plasticity‘,\n",
    "           Neurocomputing, 71. 1159-1171, 2008,\n",
    "           doi: 10.1016/j.neucom.2007.12.020.\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        seed = get_seed()\n",
    "    rs = rand_generator(seed)\n",
    "\n",
    "    y = np.zeros((n_timesteps + order, 1))\n",
    "\n",
    "    x0 = check_vector(np.atleast_2d(np.asarray(x0)))\n",
    "    y[: x0.shape[0], :] = x0\n",
    "\n",
    "    # noise = rs.uniform(0, 0.5, size=(n_timesteps + order, 1))\n",
    "    noise = np.random.uniform(0, 1, (n_timesteps + order, 1))\n",
    "    for t in range(order, n_timesteps + order - 1):\n",
    "        print(a1 * y[t], a2 * y[t], np.sum(y[t - order+1 : t+1]), b * noise[t - order], noise[t])\n",
    "        y[t + 1] = (a1 * y[t] + a2 * y[t] * np.sum(y[t - order+1 : t+1])+ b * noise[t - order] * noise[t]+ c)\n",
    "    return y[order:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.72093, 0.68895, 0.625  , ..., 0.69186, 0.63953, 0.61628]),\n",
       " array([0.72093, 0.68895, 0.625  , ..., 0.69186, 0.63953, 0.61628]),\n",
       " array([0.60465, 0.62791, 0.60174, ..., 0.77616, 0.81105, 0.7907 ]),\n",
       " array([0.60465, 0.62791, 0.60174, ..., 0.77616, 0.81105, 0.7907 ]),\n",
       " array([0.74419, 0.70349, 0.67733, ..., 0.6686 , 0.57849, 0.51453]),\n",
       " array([0.74419, 0.70349, 0.67733, ..., 0.6686 , 0.57849, 0.51453]),\n",
       " array([[0.52326, 0.46512, 0.42442, ..., 0.8343 , 0.84593, 0.79651],\n",
       "        [0.46512, 0.42442, 0.41279, ..., 0.84593, 0.79651, 0.72093],\n",
       "        [0.42442, 0.41279, 0.40407, ..., 0.79651, 0.72093, 0.68895],\n",
       "        ...,\n",
       "        [0.77616, 0.72965, 0.69767, ..., 0.74419, 0.72384, 0.6686 ],\n",
       "        [0.72965, 0.69767, 0.67442, ..., 0.72384, 0.6686 , 0.57849],\n",
       "        [0.69767, 0.67442, 0.68023, ..., 0.6686 , 0.57849, 0.51453]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def getDataSingleCol():\n",
    "    water = pd.read_csv(\"../datasets/Water.csv\").to_numpy()\n",
    "    firstRow = water[0, :]\n",
    "    lastCol = water[1:, -1]\n",
    "    allData = np.concatenate((firstRow, lastCol))\n",
    "    \n",
    "    trainLen = math.floor(len(water)*0.5)\n",
    "    valLen = math.floor(len(water)*0.7)\n",
    "    \n",
    "    train_in = lastCol[0:trainLen]\n",
    "    train_out = lastCol[0:trainLen]\n",
    "    val_in = lastCol[trainLen:valLen]\n",
    "    val_out = lastCol[trainLen:valLen]\n",
    "    test_in = lastCol[valLen:]\n",
    "    test_out = lastCol[valLen:]\n",
    "    return train_in, train_out, val_in, val_out, test_in, test_out, water\n",
    "getDataSingleCol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2],\n",
       " [0, 3],\n",
       " [0, 4],\n",
       " [0, 5],\n",
       " [1, 2],\n",
       " [1, 4],\n",
       " [1, 6],\n",
       " [2, 4],\n",
       " [2, 5],\n",
       " [2, 6],\n",
       " [3, 5],\n",
       " [4, 5],\n",
       " [5, 6]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def adjacency_matrix_to_list_pairs(adj_matrix):\n",
    "    edge_list = []\n",
    "    num_nodes = len(adj_matrix)\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if adj_matrix[i][j] == 1:\n",
    "                edge_list.append([i, j])\n",
    "    \n",
    "    return edge_list\n",
    "\n",
    "def generate_dag_adjacency_matrix(num_nodes):\n",
    "    # Create an empty adjacency matrix\n",
    "    adj_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "    \n",
    "    # Populate the adjacency matrix such that there are no cycles\n",
    "    for i in range(num_nodes - 1):  # Adjust the range to stop before the last node\n",
    "        # Nodes can only connect to subsequent nodes to ensure no cycles\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            # Introduce randomness in connections; not every node connects to every other node\n",
    "            if np.random.rand() > 0.5:\n",
    "                adj_matrix[i, j] = 1\n",
    "                \n",
    "    # Ensure there's at least one path from start (0) to end (num_nodes-1)\n",
    "    # Directly connect the start node to some node if not already connected\n",
    "    if not adj_matrix[0].any():\n",
    "        adj_matrix[0, np.random.randint(1, num_nodes - 1)] = 1  # Avoid connecting directly to the last node\n",
    "\n",
    "    # Ensure the last node can be reached from some node but does not have outgoing edges\n",
    "    if not adj_matrix[:, num_nodes - 1].any():\n",
    "        adj_matrix[np.random.randint(0, num_nodes - 1), num_nodes - 1] = 1\n",
    "\n",
    "    return adjacency_matrix_to_list_pairs(adj_matrix)\n",
    "\n",
    "generate_dag_adjacency_matrix(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "def createRandomGraph(numNodes):\n",
    "    while True:\n",
    "        G = nx.gnp_random_graph(numNodes - 2, 1, directed=True)\n",
    "        DAG = nx.DiGraph([(u, v, {'weight':random.randint(-10, 10)}) for (u, v) in G.edges() if u<v])\n",
    "        if len(DAG.nodes)==numNodes-2:\n",
    "            break\n",
    "    \n",
    "    sources = []\n",
    "    sinks = []\n",
    "    for node in DAG.nodes:\n",
    "        hasPredecessor = False\n",
    "        for otherNode in DAG.nodes:\n",
    "            if DAG.has_predecessor(node, otherNode):\n",
    "                hasPredecessor = True\n",
    "        if not hasPredecessor:\n",
    "            sources.append(node)\n",
    "            \n",
    "        hasSuccessor = False\n",
    "        for otherNode in DAG.nodes:\n",
    "            if DAG.has_successor(node, otherNode):\n",
    "                hasSuccessor = True\n",
    "        if not hasSuccessor:\n",
    "            sinks.append(node)\n",
    "\n",
    "    edges = [[0, source+1] for source in sources] + [[e1 + 1, e2 + 1] for (e1, e2) in DAG.edges] + [[sink+1, numNodes-1] for sink in sinks]\n",
    "    return edges\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 4), (1, 5), (1, 6), (2, 3), (2, 4), (2, 6), (3, 4), (3, 5), (3, 6), (4, 5), (4, 6), (5, 6)] [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 4],\n",
       " [1, 5],\n",
       " [1, 6],\n",
       " [2, 3],\n",
       " [2, 5],\n",
       " [2, 6],\n",
       " [2, 7],\n",
       " [3, 4],\n",
       " [3, 5],\n",
       " [3, 7],\n",
       " [4, 5],\n",
       " [4, 6],\n",
       " [4, 7],\n",
       " [5, 6],\n",
       " [5, 7],\n",
       " [6, 7],\n",
       " [7, 8]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createGraph(9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
